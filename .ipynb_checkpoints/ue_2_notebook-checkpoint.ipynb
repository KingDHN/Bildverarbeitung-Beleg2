{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec537176",
   "metadata": {},
   "source": [
    "# Bildverarbeitung Belegarbeit 2\n",
    "\n",
    "Willkommen zu dieser praktischen Übung zur Bildverarbeitung! In diesem Notebook werden wir uns mit fundamentalen Techniken zur Bildfilterung, Segmentierung und Merkmalsextraktion beschäftigen.\n",
    "\n",
    "Das Ziel bleibt dasselbe: Wir werden diese Methoden **von Grund auf implementieren**, um ein tiefes Verständnis für die zugrunde liegenden Algorithmen und Operationen zu entwickeln, anstatt nur fertige Bibliotheksfunktionen zu verwenden.\n",
    "\n",
    "Wir werden uns durch eine typische Pipeline der Bildanalyse arbeiten:\n",
    "\n",
    "1.  **Filter-Operatoren**: Wir beginnen mit der Rauschunterdrückung und Bildverbesserung. Sie werden zwei essenzielle Filter implementieren:\n",
    "    * Den **Median-Filter** als robusten, nicht-linearen Ansatz zur Entfernung von Ausreißern (z.B. Salz-und-Pfeffer-Rauschen).\n",
    "    * Die **2D-Faltung (conv2d)** als Basis für lineare Filter (z.B. Glättung oder Kantenhervorhebung durch eigene Filterkerne).\n",
    "\n",
    "2.  **Automatische Schwellenwertfindung (Thresholding)**: Um Bilder in Vorder- und Hintergrund zu trennen (Binarisierung), implementieren wir zwei klassische automatische Verfahren:\n",
    "    * Einen **iterativen Algorithmus**, der den Schwellenwert schrittweise verfeinert, bis er konvergiert.\n",
    "    * Die **Methode von Otsu**, ein statistischer Ansatz, der die Varianz zwischen den Klassen maximiert.\n",
    "\n",
    "3.  **Morphologische Operatoren**: Aufbauend auf den binarisierten Bildern, werden wir die **Öffnung (Opening)** implementieren. Sie lernen, wie diese Operation (eine Kombination aus Erosion und Dilatation) genutzt wird, um Rauschen zu entfernen und die Konturen von Objekten zu glätten.\n",
    "\n",
    "4.  **Hough-Transformation**: Zum Abschluss widmen wir uns der Merkmalsextraktion. Wir implementieren die Hough-Transformation, eine leistungsstarke Technik, um geometrische Formen – in unserem Fall **Linien** – in einem Bild zu detektieren, selbst wenn diese lückenhaft oder verrauscht sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a70ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22b9a0c",
   "metadata": {},
   "source": [
    "## Teil 1: Filter-Operatoren zur Rauschunterdrückung\n",
    "\n",
    "In der realen Welt sind Bilder selten perfekt. Sie enthalten oft Rauschen, das durch den Aufnahmesensor, die Datenübertragung oder andere Störungen entsteht. Das Ziel der Bildfilterung ist es, dieses Rauschen zu unterdrücken und gleichzeitig wichtige Bildstrukturen (wie Kanten) so gut wie möglich zu erhalten.\n",
    "\n",
    "In dieser ersten Aufgabe werden wir unsere Filter auf ein Bild anwenden, das mit **Salz-und-Pfeffer-Rauschen** (Salt-and-Pepper-Noise) versehen ist. Diese Rauschart zeichnet sich durch einzelne, zufällig verteilte Pixel aus, die entweder den maximalen (weiß, \"Salz\") oder den minimalen (schwarz, \"Pfeffer\") Helligkeitswert annehmen.\n",
    "\n",
    "Wir werden zwei fundamentale Filtertypen von Grund auf implementieren, um dieses Rauschen zu bekämpfen: einen linearen und einen nicht-linearen Ansatz.\n",
    "\n",
    "### Der 3x3 Box-Filter (Lineare Faltung)\n",
    "\n",
    "Der **3x3 Box-Filter** (auch Mittelwertfilter genannt) ist ein klassischer linearer Glättungsfilter. Er ersetzt den Wert jedes Pixels durch den **Durchschnittswert** aller Pixel in seiner 3x3-Nachbarschaft (also das zentrale Pixel und seine 8 Nachbarn).\n",
    "\n",
    "Dieser Vorgang wird formal durch eine Operation namens **Faltung (Convolution)** beschrieben. In vielen Implementierungen (und in unserer Übung) wird dabei die **Cross-Korrelation** berechnet, bei der der Filterkern (Kernel) *nicht* gespiegelt wird.\n",
    "\n",
    "Für ein Ausgabebild $G$, ein Eingabebild $I$ und einen 3x3-Kern $K$ ist die Operation für ein Pixel an der Koordinate $(i, j)$ definiert als:\n",
    "\n",
    "$$G(i, j) = \\sum_{u=-1}^{1} \\sum_{v=-1}^{1} K(u, v) \\cdot I(i+u, j+v)$$\n",
    "\n",
    "Für unseren 3x3 Box-Filter ist der Kern $K$ eine Matrix, bei der jedes Element den Wert $\\frac{1}{9}$ hat (da alle 9 Pixel gleich gewichtet werden und die Summe 1 ergeben muss):\n",
    "\n",
    "$$K_{\\text{Box}} = \\frac{1}{9} \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{pmatrix}$$\n",
    "\n",
    "### Der 3x3 Median-Filter (Nicht-linearer Filter)\n",
    "\n",
    "Der **3x3 Median-Filter** ist ein fundamental anderer, nicht-linearer Ansatz. Statt eines gewichteten Durchschnitts berechnet er den **Median** aller 9 Pixelwerte in der 3x3-Nachbarschaft.\n",
    "\n",
    "Dazu werden die 9 Pixelwerte der Nachbarschaft (inklusive des zentralen Pixels) gesammelt, der Größe nach **sortiert**, und der Wert, der genau in der Mitte dieser sortierten Liste steht (d.h. der 5. Wert), wird als neuer Pixelwert für die zentrale Position $(i, j)$ übernommen.\n",
    "\n",
    "Dieser Ansatz macht den Median-Filter extrem **robust gegenüber Ausreißern**. Einzelne Salz- oder Pfeffer-Pixel sind Extremwerte und landen am Anfang oder Ende der sortierten Liste, beeinflussen den Median aber kaum.\n",
    "\n",
    "---\n",
    "\n",
    "Ihre Aufgabe ist es nun, beide Filter zu implementieren und ihre Wirkung auf das verrauschte Testbild zu vergleichen. Achten Sie darauf, wie effektiv jeder Filter das Rauschen entfernt und welche Nebeneffekte (z.B. Weichzeichnung, Kantenerhaltung) dabei auftreten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17f40597",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_and_pepper = Image.open(\"karl-salt-and-pepper.jpg\")\n",
    "salt_and_pepper_array = np.array(salt_and_pepper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5854992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_conv2d_box(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply a 3x3 convolution filter to the image.\n",
    "\n",
    "    Hint:\n",
    "        - Use the padded image to handle border pixels properly.\n",
    "        - For each pixel, consider the pixel itself and its 8 neighbors.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image as a 2D numpy array.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Filtered image as a 2D numpy array.\n",
    "    \"\"\"\n",
    "    kernel = np.array([[1, 1, 1],\n",
    "                       [1, 1, 1],\n",
    "                       [1, 1, 1]]) / 9.0  # Simple averaging filter\n",
    "\n",
    "    # for a 3x3 conv2d filter, we consider the 8 neighbors and the pixel itself\n",
    "    # we need to pad 1px to the image border to receive same size output\n",
    "    padded_img = np.pad(img, pad_width=1, mode='edge')\n",
    "    filtered_img = np.zeros_like(img)\n",
    "\n",
    "    # your code here\n",
    "\n",
    "    return filtered_img\n",
    "\n",
    "def apply_median_filter(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply a 3x3 median filter to the image.\n",
    "\n",
    "    Hint:\n",
    "        - Use the padded image to handle border pixels properly.\n",
    "        - For each pixel, consider the pixel itself and its 8 neighbors.\n",
    "        - Compute the median of these 9 values (np.median) and assign it to the pixel in the output image.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image as a 2D numpy array.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Filtered image as a 2D numpy array.\n",
    "    \"\"\"\n",
    "    # for a 3x3 median filter, we consider the 8 neighbors and the pixel itself\n",
    "    # we need to pad 1px to the image border to receive same size output\n",
    "    padded_img = np.pad(img, pad_width=1, mode='edge')\n",
    "    filtered_img = np.zeros_like(img)\n",
    "    kernel_range = range(-1, 2)\n",
    "\n",
    "    # your code here\n",
    "\n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd8e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved_image = apply_conv2d_box(salt_and_pepper_array)\n",
    "median_filtered_image = apply_median_filter(salt_and_pepper_array)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "ax[0].imshow(salt_and_pepper_array, cmap='gray')\n",
    "ax[0].set_title('Original Salt and Pepper Image')\n",
    "ax[1].imshow(convolved_image, cmap='gray')\n",
    "ax[1].set_title('Convolved Image (Box Filter)')\n",
    "ax[2].imshow(median_filtered_image, cmap='gray')\n",
    "ax[2].set_title('Median Filtered Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fbe72d",
   "metadata": {},
   "source": [
    "## Teilaufgabe 2: Automatische Schwellenwertfindung (Thresholding)\n",
    "\n",
    "Nachdem wir im ersten Schritt das Rauschen im Bild reduziert haben, ist der nächste typische Schritt der Bildanalyse die **Segmentierung**. Das Ziel ist es, das Bild in sinnvolle Bereiche zu unterteilen. Die grundlegendste Form der Segmentierung ist die **Binarisierung**: Wir teilen das Bild in genau zwei Klassen auf: **Vordergrund** (Objekte von Interesse) und **Hintergrund**.\n",
    "\n",
    "Dies geschieht durch Anwenden eines **Schwellenwerts (Thresholds)** $T$. Jedes Pixel $I(i, j)$ wird überprüft:\n",
    "* Ist $I(i, j) > T$, wird es dem Vordergrund (z.B. Weiß, Wert 255) zugeordnet.\n",
    "* Ist $I(i, j) \\leq T$, wird es dem Hintergrund (z.B. Schwarz, Wert 0) zugeordnet.\n",
    "\n",
    "Die zentrale Herausforderung ist: Wie findet man den **optimalen Schwellenwert** $T$ automatisch? Ein manuell gewählter Wert funktioniert vielleicht für ein Bild, aber scheitert bei unterschiedlichen Lichtverhältnissen.\n",
    "\n",
    "In dieser Aufgabe werden wir zwei fundamentale Algorithmen implementieren, um $T$ automatisch aus den Bilddaten (dem Histogramm) abzuleiten.\n",
    "\n",
    "### Vorbereitung: Das Histogramm\n",
    "\n",
    "Beide Methoden basieren nicht auf dem Bild selbst, sondern auf dessen **Histogramm**. Das Histogramm $h(g)$ zählt, wie oft jeder Grauwert $g$ (von 0 bis 255) im Bild vorkommt. Bevor Sie die Algorithmen implementieren, werden Sie eine Funktion zur Berechnung des Histogramms eines Bildes erstellen.\n",
    "\n",
    "### 1. Der iterative Algorithmus\n",
    "\n",
    "Dieser Ansatz ist ein intuitives, schrittweises Verfahren, um sich einem stabilen Schwellenwert anzunähern.\n",
    "\n",
    "Der Algorithmus funktioniert (vereinfacht) wie folgt:\n",
    "1.  **Starte** mit einer ersten Schätzung für $T$ (z.B. dem mittleren Grauwert des gesamten Bildes).\n",
    "2.  **Segmentiere** das Bild mit diesem $T$ in zwei Gruppen: $G_1$ (Pixel $\\leq T$) und $G_2$ (Pixel $> T$).\n",
    "3.  **Berechne** den mittleren Grauwert $\\mu_1$ von $G_1$ und den mittleren Grauwert $\\mu_2$ von $G_2$.\n",
    "4.  **Setze** einen neuen Schwellenwert $T_{\\text{neu}} = \\frac{\\mu_1 + \\mu_2}{2}$.\n",
    "5.  **Wiederhole** die Schritte 2-4, bis sich $T$ nicht mehr oder nur noch minimal ändert (Konvergenz).\n",
    "\n",
    "### 2. Die Methode von Otsu\n",
    "\n",
    "Die **Methode von Otsu** ist ein \"intelligenterer\" und sehr weit verbreiteter statistischer Ansatz. Otsus Methode analysiert das **Histogramm**, um die **optimale Trennung** zwischen Vorder- und Hintergrund zu finden.\n",
    "\n",
    "Die Kernidee ist: Der Algorithmus testet jeden möglichen Grauwert $T$ (von 0 bis 255) als potenziellen Schwellenwert. Um dies effizient zu tun, nutzt der Algorithmus **kumulative Summen** (oft als kumulatives Histogramm bezeichnet), die Sie ebenfalls berechnen werden:\n",
    "\n",
    "1.  **Normalisiertes Histogramm (Wahrscheinlichkeiten)** $p(g)$: Der Anteil jedes Grauwerts an der Gesamtpixelzahl.\n",
    "2.  **Kumulative Summe (Anteil)** $w(T) = \\sum_{g=0}^{T} p(g)$: Der prozentuale Anteil der Pixel, die zur Klasse 1 (Hintergrund) gehören, wenn bei $T$ getrennt wird.\n",
    "3.  **Kumulative Summe (Mittelwerte)** $\\mu(T) = \\sum_{g=0}^{T} g \\cdot p(g)$: Die Summe der Grauwerte (gewichtet mit ihrer Wahrscheinlichkeit) bis zum Schwellenwert $T$.\n",
    "\n",
    "Mit diesen Hilfsgrößen testet der Algorithmus jeden Schwellenwert $T$ und berechnet die **Inter-Klassen-Varianz** $\\sigma^2_b(T)$ (also den \"Abstand\" zwischen den beiden Klassen). Die Formel vereinfacht sich durch die kumulativen Summen drastisch:\n",
    "\n",
    "$$\\sigma^2_b(T) = \\frac{[\\mu_{\\text{total}} \\cdot w(T) - \\mu(T)]^2}{w(T) \\cdot (1 - w(T))}$$\n",
    "\n",
    "* $\\mu_{\\text{total}}$ ist der mittlere Grauwert des gesamten Bildes.\n",
    "* $w(T)$ ist der Pixelanteil der Hintergrundklasse (aus der kumulativen Summe 2).\n",
    "* $\\mu(T)$ ist der gewichtete Mittelwert der Hintergrundklasse (aus der kumulativen Summe 3).\n",
    "\n",
    "Das Ziel ist, denjenigen Schwellenwert $T$ zu finden, der diesen Wert $\\sigma^2_b(T)$ **maximiert**. Dieser $T$ gilt als der beste Schwellenwert, um Vorder- und Hintergrund statistisch zu trennen.\n",
    "\n",
    "---\n",
    "\n",
    "Ihre Aufgabe ist es, zunächst das Histogramm und die kumulativen Summen zu berechnen und anschließend beide Thresholding-Methoden zu implementieren. Vergleichen Sie die Ergebnisse der beiden Verfahren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f962ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudoku = Image.open(\"sudoku.png\").convert(\"L\").resize((512, 512))\n",
    "sudoku_array = np.array(sudoku)\n",
    "sudoku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b47b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import histogram\n",
    "\n",
    "\n",
    "def calculate_histogram(img_array: np.ndarray, is_normalized: bool = False) -> np.ndarray:\n",
    "    \"\"\"Calculate histogram of the image array.\n",
    "\n",
    "    Hints:\n",
    "        - Use img_array.flatten() to iterate over all pixel values in a flattened manner.\n",
    "\n",
    "    Args:\n",
    "        img_array (np.ndarray): Input image array.\n",
    "        is_normalized (bool): Whether to return normalized histogram.\n",
    "    \"\"\"\n",
    "    histogram = np.zeros(256, dtype=int)\n",
    "\n",
    "    # your code here\n",
    "\n",
    "    return histogram\n",
    "\n",
    "def calculate_cumulative_histogram(histogram: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Calculate cumulative histogram from histogram.\n",
    "\n",
    "    Hints:\n",
    "        - Initialize cumulative histogram with zeros using np.zeros_like.\n",
    "        - Use a for loop to accumulate histogram values.\n",
    "        - cumulative[i] = cumulative[i - 1] + histogram[i]\n",
    "        - The first value is simply cumulative[0] = histogram[0]\n",
    "\n",
    "    Args:\n",
    "        histogram (np.ndarray): Input histogram.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Cumulative histogram.\n",
    "\n",
    "    \"\"\"\n",
    "    cumulative = np.zeros_like(histogram)\n",
    "\n",
    "    # your code here\n",
    "\n",
    "    return cumulative\n",
    "\n",
    "def find_threshold_iterative(cumulative_histogram: np.ndarray, max_iterations=20) -> int:\n",
    "    \"\"\"Iteratively find optimal threshold for image segmentation.\n",
    "\n",
    "    Hints:\n",
    "        - Start with an initial threshold T as the mean of the cumulative histogram (np.mean).\n",
    "        - In each iteration, segment the histogram into two groups based on the current threshold T.\n",
    "        - Calculate the means of both groups (mu1 and mu2).\n",
    "        - Update the threshold T_new as the average of mu1 and mu2.\n",
    "        - Check for convergence: if the change in threshold is less than a small value (e.g., 0.5), break the loop.\n",
    "        - Return the final threshold scaled to the range [0, 255].\n",
    "\n",
    "    Args:\n",
    "        histogram (np.ndarray): Histogram of the image.\n",
    "        max_iterations (int): Maximum number of iterations to perform.\n",
    "\n",
    "    Returns:\n",
    "        int: Optimal threshold value.\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "\n",
    "\n",
    "\n",
    "def find_threshold_by_otsu(normalized_histogram: np.ndarray, cumulative_histogram: np.ndarray) -> int:\n",
    "    \"\"\"Find optimal threshold using Otsu's method.\n",
    "\n",
    "    Hints:\n",
    "        - Initialize an array to hold variance values for each threshold.\n",
    "        - Loop through all possible threshold values (0 to 255).\n",
    "        - For each threshold T, calculate the probabilities P_0 and P_1, taking into account the cumulative histogram.\n",
    "        - Calculate the means mu_0 and mu_1 for the two classes.\n",
    "        - Compute the between-class variance using the formula: variance = P_0 * P_1 * (mu_0 - mu_1) ** 2\n",
    "        - Store the variance for each threshold.\n",
    "        - Return the threshold that maximizes the between-class variance (np.argmax).\n",
    "\n",
    "    Args:\n",
    "        normalized_histogram (np.ndarray): Normalized histogram of the image.\n",
    "        cumulative_histogram (np.ndarray): Cumulative histogram of the image.\n",
    "\n",
    "    Returns:\n",
    "        int: Optimal threshold value.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef26d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram = calculate_histogram(sudoku_array)\n",
    "cumulative_histogram = calculate_cumulative_histogram(histogram)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ax[0].imshow(sudoku_array, cmap='gray')\n",
    "ax[0].set_title('Sudoku Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].bar(range(256), histogram, width=1.0, color='blue', alpha=0.7)\n",
    "ax[1].set_xlabel('Gray Value')\n",
    "ax[1].set_ylabel('Frequency')\n",
    "ax[1].set_title('Histogram of Sudoku Image')\n",
    "ax[1].set_xlim(0, 255)\n",
    "\n",
    "ax[2].bar(range(256), cumulative_histogram, width=1.0, color='green', alpha=0.7)\n",
    "ax[2].set_xlabel('Gray Value')\n",
    "ax[2].set_ylabel('Cumulative Frequency')\n",
    "ax[2].set_title('Cumulative Histogram of Sudoku Image')\n",
    "ax[2].set_xlim(0, 255)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793e454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_histogram = calculate_histogram(sudoku_array, is_normalized=True)\n",
    "normalized_cumulative_histogram = calculate_cumulative_histogram(normalized_histogram)\n",
    "\n",
    "iterative_threshold = find_threshold_iterative(normalized_cumulative_histogram)\n",
    "otsu_threshold = find_threshold_by_otsu(normalized_histogram, normalized_cumulative_histogram)\n",
    "\n",
    "# Apply thresholding\n",
    "iterative_segmented = (sudoku_array <= iterative_threshold).astype(np.uint8) * 255\n",
    "otsu_segmented = (sudoku_array <= otsu_threshold).astype(np.uint8) * 255\n",
    "\n",
    "# Plot results\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "ax[0].imshow(sudoku_array, cmap='gray')\n",
    "ax[0].set_title('Original Sudoku Image')\n",
    "ax[1].imshow(iterative_segmented, cmap='gray')\n",
    "ax[1].set_title(f'Iterative Threshold (T = {iterative_threshold})')\n",
    "ax[2].imshow(otsu_segmented, cmap='gray')\n",
    "ax[2].set_title(f'Otsu Threshold (T = {otsu_threshold})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c142e371",
   "metadata": {},
   "source": [
    "## Teilaufgabe 3: Morphologische Operatoren\n",
    "\n",
    "Nachdem wir in Teil 2 gelernt haben, wie man ein Graustufenbild in ein **Binärbild** (Schwarz-Weiß) umwandelt, ist der nächste Schritt oft die \"Bereinigung\" dieses Bildes. Das Ergebnis einer Schwellenwertbildung ist selten perfekt: Es kann kleine, isolierte \"Rauschpixel\" (sowohl schwarze Löcher im Vordergrund als auch weiße Flecken im Hintergrund) oder dünne \"Brücken\", die Objekte fälschlicherweise verbinden, enthalten.\n",
    "\n",
    "Hier kommen **morphologische Operatoren** ins Spiel. Dies sind nicht-lineare Operationen, die auf der **Form** (oder Morphologie) von Objekten in einem Bild arbeiten. Sie werden verwendet, um die Struktur von Binärbildern zu analysieren und zu modifizieren.\n",
    "\n",
    "### Das Strukturelement (SE)\n",
    "\n",
    "Alle morphologischen Operationen basieren auf einem **Strukturelement (SE)**. Dies ist ein kleiner \"Kernel\" (ähnlich wie unser Faltungskern), der als \"Sonde\" über das Bild geschoben wird. Für unsere Aufgabe verwenden wir ein einfaches 3x3-Quadrat als SE:\n",
    "\n",
    "$$SE = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{pmatrix}$$\n",
    "\n",
    "### Die Grundoperationen: Erosion und Dilatation\n",
    "\n",
    "Die beiden fundamentalen Operationen, aus denen fast alle anderen abgeleitet werden, sind Erosion und Dilatation.\n",
    "\n",
    "1.  **Erosion (Schrumpfen)**:\n",
    "    Die Erosion *verkleinert* die Grenzen von Vordergrundobjekten (weiße Bereiche). Ein Pixel im Ausgabebild wird *nur dann* auf Weiß (1) gesetzt, wenn das **gesamte** Strukturelement, zentriert auf diesem Pixel, **vollständig** auf Vordergrundpixel im Eingabebild passt.\n",
    "    * **Effekt**: Dünne Linien und isolierte weiße Pixel (Rauschen) werden komplett entfernt. Objekte schrumpfen.\n",
    "\n",
    "2.  **Dilatation (Wachsen)**:\n",
    "    Die Dilatation *vergrößert* die Grenzen von Vordergrundobjekten. Ein Pixel im Ausgabebild wird auf Weiß (1) gesetzt, wenn das Strukturelement, zentriert auf diesem Pixel, **mindestens ein** Vordergrundpixel im Eingabebild \"trifft\" (überlappt).\n",
    "    * **Effekt**: Kleine schwarze Löcher in Objekten werden gefüllt. Objekte wachsen und können miteinander verschmelzen.\n",
    "\n",
    "### Unsere Ziel-Operation: Die Öffnung (Opening)\n",
    "\n",
    "In dieser Aufgabe implementieren wir die **Öffnung (Opening)**. Diese Operation ist definiert als eine **Erosion, *gefolgt* von einer Dilatation** (mit demselben Strukturelement).\n",
    "\n",
    "Warum diese Kombination?\n",
    "1.  Die **Erosion** entfernt zunächst alle kleinen Rauschpixel (wie in Teil 1 das \"Salz\"-Rauschen, nur jetzt im Binärbild) und bricht dünne Brücken zwischen Objekten auf. Größere Objekte schrumpfen dabei.\n",
    "2.  Die anschließende **Dilatation** vergrößert die verbliebenen (bereinigten) Objekte wieder auf ungefähr ihre ursprüngliche Größe. Wichtig dabei: Das Rauschen, das im ersten Schritt entfernt wurde, \"wächst nicht nach\"!\n",
    "\n",
    "Der Nettoeffekt der Öffnung ist also die **Entfernung kleiner Objekte und die Glättung von Konturen**, ohne die Größe der Hauptobjekte signifikant zu verändern.\n",
    "\n",
    "---\n",
    "\n",
    "Ihre Aufgabe ist es, die Operationen **Erosion** und **Dilatation** von Grund auf zu implementieren und diese dann zur **Öffnung** zu kombinieren. Wenden Sie Ihre Implementierung auf die Binärbilder aus Teil 2 an und beobachten Sie den Bereinigungseffekt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8f195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_binary_erosion(img: np.ndarray, structuring_element: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply binary erosion to the binary image using the given structuring element.\n",
    "\n",
    "\n",
    "    Hint:\n",
    "        - For each pixel in the image, check if the structuring element fits entirely within the foreground (1s) of the image.\n",
    "        - Use nested loops to iterate over each pixel and the structuring element.\n",
    "        - If all pixels under the structuring element are 1s, set the output pixel to 1; otherwise, set it to 0.\n",
    "        - Any pixel outside the image boundaries should be considered as 0.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input binary image as a 2D numpy array.\n",
    "        structuring_element (np.ndarray): Structuring element as a 2D numpy array.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Eroded binary image as a 2D numpy array.\n",
    "    \"\"\"\n",
    "    if structuring_element.shape[0] != 3 or structuring_element.shape[1] != 3:\n",
    "        raise ValueError(\"Structuring element must be of size 3x3.\")\n",
    "\n",
    "    eroded_img = np.zeros_like(img)\n",
    "    se_range = range(-1, 2)\n",
    "\n",
    "    # your code here\n",
    "\n",
    "    return eroded_img\n",
    "\n",
    "def apply_binary_dilation(img: np.ndarray, structuring_element: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply binary dilation to the binary image using the given structuring element.\n",
    "\n",
    "    Hint:\n",
    "        - For each pixel in the image, check if the structuring element overlaps with any foreground (1s) of the image.\n",
    "        - Use nested loops to iterate over each pixel and the structuring element.\n",
    "        - If any pixel under the structuring element is a 1, set the output pixel to 1; otherwise, set it to 0.\n",
    "        - Any pixel outside the image boundaries should be considered as 0.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input binary image as a 2D numpy array.\n",
    "        structuring_element (np.ndarray): Structuring element as a 2D numpy array.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Dilated binary image as a 2D numpy array.\n",
    "    \"\"\"\n",
    "    if structuring_element.shape[0] != 3 or structuring_element.shape[1] != 3:\n",
    "        raise ValueError(\"Structuring element must be of size 3x3.\")\n",
    "\n",
    "    dilated_img = np.zeros_like(img)\n",
    "    se_range = range(-1, 2)\n",
    "\n",
    "    # your code here\n",
    "\n",
    "    return dilated_img\n",
    "\n",
    "def apply_binary_opening(img: np.ndarray, structuring_element: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply binary opening to the binary image using the given structuring element.\n",
    "\n",
    "    Hint:\n",
    "        - Apply erosion followed by dilation using the same structuring element.\n",
    "        - This will remove small objects from the foreground and smooth the boundaries.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input binary image as a 2D numpy array.\n",
    "        structuring_element (np.ndarray): Structuring element as a 2D numpy array.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Opened binary image as a 2D numpy array.\n",
    "    \"\"\"\n",
    "    # your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "otsu_segmented = (sudoku_array <= otsu_threshold).astype(np.bool) # not * 255 because we are in binary space now\n",
    "\n",
    "kernel = np.array([[0, 1, 0],\n",
    "                   [1, 1, 1],\n",
    "                   [0, 1, 0]], dtype=np.uint8)\n",
    "\n",
    "\n",
    "eroded_img = apply_binary_erosion(otsu_segmented, structuring_element=kernel)\n",
    "dilated_img = apply_binary_dilation(otsu_segmented, structuring_element=kernel)\n",
    "opened_img = apply_binary_opening(otsu_segmented, structuring_element=kernel)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 6))\n",
    "ax[0].imshow(otsu_segmented, cmap='gray')\n",
    "ax[0].set_title('Original Binary Image (Otsu Segmented)')\n",
    "ax[1].imshow(eroded_img, cmap='gray')\n",
    "ax[1].set_title('Eroded Image')\n",
    "ax[2].imshow(dilated_img, cmap='gray')\n",
    "ax[2].set_title('Dilated Image')\n",
    "ax[3].imshow(opened_img, cmap='gray')\n",
    "ax[3].set_title('Opened Image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b43832",
   "metadata": {},
   "source": [
    "## Teilaufgabe 4: Die Hough-Transformation zur Linienerkennung\n",
    "\n",
    "Nachdem wir unser Bild gefiltert (Teil 1), binarisiert (Teil 2) und morphologisch bereinigt (Teil 3) haben, besitzen wir nun eine saubere Darstellung der Bildobjekte. Der nächste logische Schritt in vielen Bildverarbeitungs-Pipelines ist die **Merkmalsextraktion**: Wir wollen die Objekte nicht nur *sehen*, sondern sie auch *beschreiben* oder *finden*.\n",
    "\n",
    "In dieser letzten Aufgabe implementieren wir die **Hough-Transformation**, eine fundamentale und leistungsstarke Technik, um geometrische Grundformen – in unserem Fall **Linien** – in einem Bild zu detektieren.\n",
    "\n",
    "### Die Herausforderung\n",
    "\n",
    "Das Finden von Linien in einem Bild ist nicht trivial. Eine Linie kann lückenhaft sein (gestrichelt), teilweise verdeckt oder durch Rauschen gestört sein. Ein Algorithmus, der einfach versucht, benachbarte Pixel zu verbinden, würde hier schnell scheitern.\n",
    "\n",
    "### Die Kernidee: Vom Bildraum zum Parameterraum\n",
    "\n",
    "Die Hough-Transformation löst dieses Problem durch einen cleveren \"Trick\": Sie verwendet ein **Abstimmungsverfahren (Voting)**. Statt im Bildraum (x, y) nach Linien zu suchen, wandelt sie jeden Punkt in einen \"Parameterraum\" um und lässt die Punkte dort für alle Linien \"abstimmen\", zu denen sie gehören *könnten*.\n",
    "\n",
    "Für die Linienerkennung verwenden wir die **Hessesche Normalform** zur Darstellung einer Linie:\n",
    "\n",
    "$$\\rho = x \\cdot \\cos(\\theta) + y \\cdot \\sin(\\theta)$$\n",
    "\n",
    "* $(x, y)$ sind die Koordinaten eines Pixels im Bild.\n",
    "* $\\rho$ (rho) ist der senkrechte Abstand der Linie vom Ursprung (0, 0).\n",
    "* $\\theta$ (theta) ist der Winkel der Normalen (der Senkrechten) dieser Linie zur x-Achse.\n",
    "\n",
    "\n",
    "\n",
    "**Der Clou:**\n",
    "1.  Ein einzelner Punkt $(x, y)$ im Bildraum entspricht einer **Sinuskurve** im $(\\rho, \\theta)$-Parameterraum (dem \"Hough-Raum\"), denn für ein festes $(x, y)$ gibt es unendlich viele Linien (unendlich viele Paare von $\\rho$ und $\\theta$), die durch diesen Punkt gehen.\n",
    "2.  Liegen mehrere Punkte $(x_1, y_1), (x_2, y_2), ...$ im Bildraum auf derselben Linie (z.B. mit den Parametern $\\rho_{\\text{linie}}$ und $\\theta_{\\text{linie}}$), **schneiden sich ihre jeweiligen Sinuskurven** im Hough-Raum alle in *genau einem Punkt*: $(\\rho_{\\text{linie}}, \\theta_{\\text{linie}})$.\n",
    "\n",
    "### Der Akkumulator\n",
    "\n",
    "Ihre Aufgabe ist es, diesen Abstimmungsprozess zu implementieren:\n",
    "1.  Sie erstellen eine 2D-Matrix, den sogenannten **Akkumulator**. Dieses 2D-Histogramm repräsentiert den diskretisierten $(\\rho, \\theta)$-Raum (z.B. $\\theta$ von $0^\\circ$ bis $180^\\circ$ und $\\rho$ von $-D$ bis $+D$, wobei $D$ die Bilddiagonale ist).\n",
    "2.  Sie iterieren über **jedes weiße Pixel** $(x, y)$ in Ihrem **bereinigten Binärbild** (dem Ergebnis der Öffnung aus Teil 3).\n",
    "3.  Für jedes dieser Pixel berechnen Sie die zugehörige Sinuskurve im Hough-Raum (indem Sie $\\theta$ von $0^\\circ$ bis $180^\\circ$ durchlaufen und das jeweilige $\\rho$ berechnen).\n",
    "4.  Für jeden Punkt $(\\rho, \\theta)$ auf dieser Kurve **erhöhen Sie den Zähler (Vote)** in der entsprechenden Zelle des Akkumulators.\n",
    "\n",
    "Am Ende dieses Vorgangs entsprechen die Zellen im Akkumulator mit den **höchsten Werten (Peaks)** den dominantesten Linien im Bild. Die Koordinaten $(\\rho, \\theta)$ dieser Peaks sind die Parameter der gefundenen Linien.\n",
    "\n",
    "**Warum das Bild aus Teil 3?** Wir verwenden das Ergebnis der morphologischen Öffnung, da es Rauschpixel entfernt hat. Jedes Rauschpixel würde fälschlicherweise für hunderte von Linien \"stimmen\" und den Akkumulator \"verschmutzen\". Durch die saubere Eingabe wird unsere Linienerkennung wesentlich robuster und genauer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569b91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_hough_transform(binary_image:np.ndarray, top_k:int=5) -> tuple[list[tuple[int, int]], np.ndarray]:\n",
    "    \"\"\"Apply Hough Transform to detect lines in the image.\n",
    "\n",
    "\n",
    "    Hints:\n",
    "        - Initialize the Hough accumulator array with zeros. The shape should be (2 * max_acc, max_angle_deg).\n",
    "        - Loop through each pixel in the binary image. If the pixel is an edge (255), loop through all possible theta values (0 to 180 degrees).\n",
    "        - For each theta, calculate rho using the formula: rho = x * cos(theta) + y * sin(theta).\n",
    "        - Increment the corresponding cell in the Hough accumulator.\n",
    "        - After populating the Hough accumulator, find the top_k lines by locating the highest values in the accumulator (np.argmax).\n",
    "        - Return the list of detected lines in (rho, theta) format and the Hough accumulator array.\n",
    "        - np.deg2rad can be used to convert degrees to radians.\n",
    "        - np.cos and np.sin can be used to compute cosine and sine values.\n",
    "        - np.sqrt can be used to compute the square root.\n",
    "        - np.argmax return a flattened index, use np.unravel_index to convert it the proper, rho, theta coordinates\n",
    "\n",
    "    Args:\n",
    "        binary_image (np.ndarray): Binary image array where edges are marked with 255.\n",
    "        top_k (int): Number of top lines to return based on votes.\n",
    "\n",
    "    Returns:\n",
    "        hough_lines (list of tuples): List of detected lines in (rho, theta) format.\n",
    "        hough_space (np.ndarray): The Hough accumulator array.\n",
    "\n",
    "    \"\"\"\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5def28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_hough_lines(image_array: np.ndarray, hough_lines: np.ndarray, hough_space: np.ndarray):\n",
    "    \"\"\"Visualize detected Hough lines on the image.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "    # Plot original image with detected lines\n",
    "    ax1.imshow(image_array, cmap='gray')\n",
    "\n",
    "    height, width = image_array.shape\n",
    "\n",
    "    for rho, theta in hough_lines:\n",
    "        theta = np.deg2rad(theta)\n",
    "        # Convert polar coordinates to line endpoints\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "\n",
    "        # Calculate line endpoints (extended beyond image boundaries)\n",
    "        x1 = int(x0 + 1000 * (-b))\n",
    "        y1 = int(y0 + 1000 * (a))\n",
    "        x2 = int(x0 - 1000 * (-b))\n",
    "        y2 = int(y0 - 1000 * (a))\n",
    "\n",
    "        ax1.plot([x1, x2], [y1, y2], 'r-', linewidth=2, alpha=0.7)\n",
    "\n",
    "    ax1.set_xlim(0, width)\n",
    "    ax1.set_ylim(height, 0)\n",
    "    ax1.set_title(f'Detected Hough Lines (top {len(hough_lines)})')\n",
    "    ax2.imshow(hough_space, cmap='hot', aspect='auto')\n",
    "    ax2.set_xlabel('Theta (degrees)')\n",
    "    ax2.set_ylabel('Rho')\n",
    "    ax2.set_title('Hough Space')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc0a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "normalized_histogram = calculate_histogram(sudoku_array, is_normalized=True)\n",
    "normalized_cumulative_histogram = calculate_cumulative_histogram(normalized_histogram)\n",
    "\n",
    "iterative_threshold = find_threshold_iterative(normalized_cumulative_histogram)\n",
    "binary_img = (sudoku_array <= iterative_threshold).astype(np.uint8) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2321d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hough_lines, hough_space = apply_hough_transform(binary_img, top_k=30)\n",
    "visualize_hough_lines(sudoku_array, hough_lines, hough_space)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bildverarbeitung-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
